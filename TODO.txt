
/* TODO */

- Create BitStream type ( Should be able to output to memory, as well as to files )
- Compress the file effectively and compare estimated compression ratio to real compression ratio ( SHould be the quite the same as the prediction on block is quite easy... )
  * Header should be defined this way
    One Byte : Number of symbols
    Then for each symbol  
    Code length size special bit: 1 bit 
    Code length : 4 bit if previous is zero, 8 bit if previous is 1	
    Actual code : 1 bit for each bit of the code
  Compressing Huffman Tree Header ? GET INFO !!
-   Test Decompression ( MD5 SUM )

FUTURE :

    *Fixed size compression block size or symbol count seems a no go.  
    
    * Compression Max Performance : what can be achieved by Brute Force ( Trying every symbol count for each block ) ?. Conclude. Is it time to implement the second part of compression ?
   
    * Adptative compression. GET INFO !! REREAD DEFLATE !!
     Currently, we need to recompute the whole tree each time a symbol is added in order to
have a size estimation.
    IDEA : Is there a way to dynamicly add new symbol to the tree and reorganize it, avoiding a whole rebuild ? kind of Dynamic Huffman Tree
    
     	


